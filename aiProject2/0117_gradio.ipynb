{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 분류 예제(Gradio 예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\241223\\aiProject2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "\u001b[1m14536120/14536120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "#TensorFlow MobileNetV2 모델 로드\n",
    "model=tf.keras.applications.MobileNetV2(weights=\"imagenet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_url):\n",
    "    try:\n",
    "        #URL에서 이미지 가져오기\n",
    "        response=requests.get(image_url);\n",
    "        image=Image.open(BytesIO(response.content)).resize((224,224));  #BytesIO 사용하여 이미지 열기\n",
    "        \n",
    "        #이미지를 배열로 변환\n",
    "        image_array=tf.keras.preprocessing.image.img_to_array(image);\n",
    "        image_array=tf.expand_dims(image_array, axis=0)     #배치 차원 추가\n",
    "        image_array=tf.keras.applications.mobilenet_v2.preprocess_input(image_array);   #전처리\n",
    "        \n",
    "        #예측 수행\n",
    "        predictions=model.predict(image_array);\n",
    "        decoded_predictions=tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0];   #상위 3개 예측결과 반환\n",
    "        \n",
    "        #Gradio Label 컴포넌트에 맞게 결과 형식 변경\n",
    "        #{label: confidence1, label2: confidence2, ...} 형식으로 반환\n",
    "        result={label: float(prob) for (_, label, prob) in decoded_predictions}\n",
    "        return result;\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1.0}   #에러 발생 시 기본갑 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "#Gradio 인터페이스 생성\n",
    "iface=gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n",
    "    outputs=gr.Label(num_top_classes=3, label=\"예측결과\"),\n",
    "    title=\"음식 이미지 분류\",\n",
    "    description=\"이미지 URL을 입력하면 상위 3개의 예측 결과를 확률과 함께 표시합니다.\"\n",
    ")\n",
    "\n",
    "#인터페이스 실행\n",
    "iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True);\n",
    "# 예시 이미지 URL : https://health.chosun.com/site/data/img_dir/2024/04/19/2024041901914_0.jpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#자원 반환\n",
    "iface.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 분류 예제(Gradio+gemma2 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\241223\\aiProject2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "#TensorFlow MobileNetV2 모델 로드\n",
    "model=tf.keras.applications.MobileNetV2(weights=\"imagenet\");\n",
    "\n",
    "OLLAMA_SERVER=\"http://localhost:11434\"; #로컬 서버주소\n",
    "MODEL_NAME=\"gemma2\"     #사용하려는 Ollama 모델 이름\n",
    "\n",
    "#Ollama를 사용해 음식 설명 생성\n",
    "def get_food_description_with_langchain(food_name):\n",
    "    \"\"\"\n",
    "    LangChain ChatOllama를 사용하여 음식 설명 생성\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat=ChatOllama(base_url=OLLAMA_SERVER, model=MODEL_NAME);\n",
    "        prompt=f\"Tell me about {food_name}.\";\n",
    "        response=chat.predict(prompt);\n",
    "        return response;\n",
    "    except Exception as e:\n",
    "        return f\"Failed to retrieve description: {e}\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 예측 함수\n",
    "def predict_image_with_description(image_url):\n",
    "    \"\"\"\n",
    "    이미지 URL을 받아 음식 예측과 Ollama 설명을 반환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #URL에서 이미지 가져오기\n",
    "        response=requests.get(image_url);\n",
    "        image=Image.open(BytesIO(response.content)).resize((224,224))   #BytesIO 사용하여 이미지 열기\n",
    "        \n",
    "        #이미지를 배열로 변환\n",
    "        image_array=tf.keras.preprocessing.image.img_to_array(image);\n",
    "        image_array=tf.expand_dims(image_array, axis=0) #배치차원 추가\n",
    "        image_array=tf.keras.applications.mobilenet_v2.preprocess_input(image_array);   #전처리\n",
    "        \n",
    "        #예측 수행\n",
    "        predictions=model.predict(image_array);\n",
    "        decoded_predictions=tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0];   #상위 3개 예측 결과 반환\n",
    "        \n",
    "        #예측결과 형식화\n",
    "        result={label: float(prob) for (_, label, prob) in decoded_predictions}\n",
    "        \n",
    "        #가장 높은 확률의 예측값으로 Ollama 설명 생성\n",
    "        top_food=decoded_predictions[0][1];     #가장 확률이 높은 음식이름\n",
    "        description=get_food_description_with_langchain(top_food);\n",
    "        \n",
    "        return result, description;   #예측 결과와 Ollama 설명 반환\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1.0}, f\"Error: {e}\"    #에러 발생 시 기본값 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7863\n",
      "* Running on public URL: https://21b9195ef9fed82e86.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://21b9195ef9fed82e86.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human-10\\AppData\\Local\\Temp\\ipykernel_13324\\1703203776.py:21: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  chat=ChatOllama(base_url=OLLAMA_SERVER, model=MODEL_NAME);\n",
      "C:\\Users\\human-10\\AppData\\Local\\Temp\\ipykernel_13324\\1703203776.py:23: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response=chat.predict(prompt);\n"
     ]
    }
   ],
   "source": [
    "#Gradio 인터페이스 생성\n",
    "iface=gr.Interface(\n",
    "    fn=predict_image_with_description,\n",
    "    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=3, label=\"예측결과\"),      #상위 3개 예측결과\n",
    "        gr.Textbox(label=\"음식 설명\", interactive=False)    #Ollama로 생성한 설명 출력\n",
    "    ],\n",
    "    title=\"음식 이미지 분류 및 설명 생성기\",\n",
    "    description=\"이미지 URL을 입력하면 음식 분류 결과와 설명을 제공합니다.\"\n",
    ");\n",
    "\n",
    "#인터페이스 실행\n",
    "iface.launch(server_port=7863, server_name=\"0.0.0.0\", debug=True, share=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#자원 반환\n",
    "iface.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
