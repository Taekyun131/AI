분류

로지스틱 회귀


//훈련데이터와 테스트 데이터를 분리하는 이유

1. 과적합 방지
훈련 데이터를 사용하여 모델을 학습시키면, 모델은 해당 훈련 데이터에 맞춰 최적화된다.
만약 모델이 훈련 데이터에서 너무 잘 맞춰지면, 새로운 데이터(테스트 데이터)에 대해서는 성능이 떨어질 수 있따.
이를 과적합(Overfitting)이라고 한다.

과적합을 방지하려면 모델이 훈련 데이터에서만 잘 예측하고, 새로운 데이터에서도 잘 예측하는지 확인할 필요가 있다.
테스트 데이터는 모델을 학습할 때 사용하지 않은 데이터로, 
모델이 실제로 일반화된 성능을 보이는지 확인할 수 있는 중요한 기준이 된다.

2. 일반화 성능 평가
훈련 데이터는 모델을 학습시키는 데 사용되지만 ,테스트 데이터는 모델을 학습하는 데 사용되지 않는다.
이렇게 데이터를 분리하여, 모델이 훈련된 데이터뿐만 아니라
보지 않은 새로운 데이터에 대해 얼마나 잘 예측하는지 평가할 수 있다.
이 평가를 통해 모델이 일반화된 성능을 가졌는지, 
즉 실제 상황에서 얼마나 잘 동작할지를 예측할 수 있다.

3. 모델 선택 및 튜닝
훈련 데이터와 테스트 데이터를 분리함으로써, 모델을 선택하고 하이퍼파라미터를 튜닝할 때
더 정확하게 모델의 성능을 평가할 수 있다.
예를 들어, 여러 모델을 비교하거나, 학습률, 정규화 강도 등 하이퍼파라미터를 최적화할 때
항상 테스트 데이터를 보지 않게 해야 한다.
테스트 데이터는 최종 모델을 평가하는 데만 사용되어야 한다.
테스트 데이터를 미리 보게 되면 모델이 테스트 데이터에 맞게 과적합 될 수 있다.

4. 훈련과 평가의 구분
훈련 데이터를 사용하여 모델을 훈련시키고, 테스트 데이터를 사용하여 그 훈련된 모델의 성능을 평가하는 것이 중요하다.
-훈련 데이터: 모델을 학습싴고, 모델이 데이터를 어떻게 이해하고 예측하는지 학습하는 데 사용
-테스트 데이터: 모델이 훈련되지 않은 새로운 데이터에 대해 얼마나 잘 예측하는지 평가하는 데 사용

5. 성능 평가의 신뢰성 확보
훈련데이터와 테스트 데이터를 분리함으로써, 모델의 성능 평가가 더 신뢰할 수 있게 된다.
테스트 데이터는 모델이 실제로 예측해야 하는 새로운 데이터셋을 시뮬레이션하며, 
이를 통해 실제 운영 환경에서 모델이 얼마나 잘 동작할지 예측할 수 있다.
 



-의사결정나무
의사결정나무는 분류와 회귀 문제를 해결하기 위해 사용되는 예측모델
데이터의 특징을 기준으로 결정을 내리는 트리형태의 모델
각 분기점에서는 특정 조건에 따라 데이터를 분할하며,
결과적으로 트리의 끝에 있는 리프노드에서 예측값을 반환


-나이브 베이즈
주어진 데이터의 특성들(변수들)이 서로 독립적이라고 가정하고 이를 바탕으로 분류를 수행하는 방식
텍스트 분류, 스팸 이메일 필터링, 감정 분석 등에서 많이 사용


-트리의 개수, 최대깊이에 대한 설명
n_estimators와 max_depth 하이퍼파라미터는 랜덤 포레스트 모델의 성능에 중요한 영향을 미칩니다.
n_estimators는 모델의 복잡도와 안정성을 조절하고, max_depth는 각 트리의 복잡도와 과적합을 조절합니다.
하이퍼파라미터 튜닝을 통해 정확도를 최적화하고, 과적합과 과소적합을 방지할 수 있습니다.

1. n_estimators (트리의 개수)
n_estimators는 랜덤 포레스트에서 생성할 트리의 개수를 지정하는 하이퍼파라미터입니다. 랜덤 포레스트는 여러 개의 결정 트리(Decision Tree)를 결합한 앙상블 모델입니다. 이 값이 모델에 미치는 영향은 다음과 같습니다:

트리 개수가 많을수록:
모델의 성능이 더 안정적이고, 더 정확할 가능성이 높습니다. 더 많은 트리가 투입될수록 모델이 다양한 패턴을 학습할 수 있고, 예측의 변동성을 줄여줍니다.
그러나 너무 많은 트리를 사용하면 연산 시간이 늘어나고, 모델이 과도하게 커질 수 있습니다. 이로 인해 학습 시간이 오래 걸리고, 예측에도 시간이 많이 소요될 수 있습니다.
트리 개수가 적을수록:
모델이 덜 복잡하고, 예측이 덜 정확할 수 있습니다. 트리가 적으면 모델이 데이터의 복잡한 패턴을 잘 포착하지 못할 수 있습니다.
예측이 빠르고, 계산 자원을 적게 사용할 수 있지만, 정확도가 낮아질 가능성이 큽니다.
2. max_depth (트리의 최대 깊이)
max_depth는 각 결정 트리의 최대 깊이를 제한하는 하이퍼파라미터입니다. 트리의 깊이는 트리가 얼마나 복잡해질 수 있는지를 결정합니다.

max_depth 값이 클수록:

트리가 더 깊고 복잡해집니다. 이는 모델이 학습 데이터를 더 세밀하게 구분할 수 있음을 의미합니다. 이로 인해 **과적합(overfitting)**이 발생할 수 있습니다. 과적합은 모델이 훈련 데이터에 너무 맞춰져서, 새로운 데이터(테스트 데이터)에서는 성능이 떨어지는 문제를 발생시킵니다.
트리가 깊을수록 더 많은 특징을 고려하고, 데이터에서 세부적인 패턴을 찾으려 합니다. 그러나 이는 모델이 너무 복잡해져, 테스트 데이터에 대한 예측 정확도가 떨어질 수 있습니다.
max_depth 값이 작을수록:

트리가 더 얕고 단순해집니다. 트리의 깊이가 얕으면 모델은 학습 데이터에서 중요한 패턴을 놓칠 수 있습니다. 이는 모델이 과소적합(underfitting) 상태에 빠지게 만들 수 있습니다. 과소적합은 모델이 학습 데이터에 충분히 적합하지 않아 예측 성능이 낮아지는 문제입니다.
그러나 모델이 간단하고 일반화 능력이 좋아 테스트 데이터에 대해 좋은 성능을 낼 가능성이 높습니다.
