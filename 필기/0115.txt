LLM(Large Language Model, 거대언어모델)
다량의 텍스트 데이터를 기반으로 문맥을 이해하고, 자연스러운 언어를 생성할 수 있는 딥러닝 기반 모델
-대규모 데이터학습
-문맥이해
-다양한 작업 수행 가능
-사전학습 및 미세조정

자연어 처리(NLP)
컴퓨터가 인간의 언어를 이해하고, 처리하며, 생성할 수 있도록 하는 기술
-토크나이징: 문장을 단어, 형태소 또는 서브 워드 단위로 나누는 과정
                쪼개진 단위를 토큰이라고 부름
-인코딩: 토크나이징된 결과를 숫자로 변환하는 과정
-임베딩: 숫자로 변환된 단어를 고차원의 실수벡터로 변환하는 과정
           벡터는 단어 간의 유사성과 문맥정보를 표현

트랜스포머
기존의 순환신경망, LSTM 및 합성곱 신경망이 가진 한계를 극복하여 LLM 기술 핵심기반
attention 매커니즘: 단어간의 연관성을 계산하여 중요한 단어에 집중
self-attention: 문장내의 모든 단어가 서로 얼마나 연관성이 있는 지 계산하는 과정
병렬처리: RNN과 달리 병렬처리가 가능하여 빠른 학습과 추론 속도를 제공, 대규모 데이터 효육적으로 처리가능
-인코더: 입력문자을 이해하고, 이를 벡터표현으로 변환하는 역할
-디코더: 인코더에서 생성된 벡터표현을 바탕으로 새로운 문장을 생성
-파이프라인: 텍스트가 모델이 이해할 수 있는 형태로 전처리 과정을 거침
	    전처리된 입력이 모델 입력으로 들어감
 	    모델의 예측값이 후처리를 거쳐, 사람이 이해할 수 있는 형태로 반환


랭체인
LLM을 활용한 응용 프로그램을 개발할 수 있는 프레임워크
주로 챗봇, 문서요약, 질문 응답 시스템을 구현할 때 사용


