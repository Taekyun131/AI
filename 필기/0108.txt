딥러닝

활성화 함수-인공 신경망에서 출력값을 결정하는 데 사용되는 함수
-시그모이드 함수: 입력값을 0~1사이의 확률값으로 변환하는 비선형 함수(S자)
 신경망에서 확률적 해석이 필요한 경우 사용
 입력값이 매우 크거나 작을 때, 기울기가 거의 0에 수렴해 기울기 소실문제 발생

-Tanh 함수: 입력값을 -1~1사이로 정규화하는 대칭적 비선형 함수
 대칭성으로 인해 학습속도 개선가능

-ReLU 함수: 음수 입력에 대해 0을 출력, 양수입력에 대해 선형적으로 출력
 계산의 단순성과 빠른 수렴으로 계산 복잡도가 낮아 학습속도 향상
 기울기 소실문제 해결하고 있으나, 출력값이 무한대로 커질 수 있음

-Softmax 함수: 입력값을 0~1사이로 변환하여 출력하지만, 전체 출력값의 합이 1이 되도록 정규화
 확률분포반환, 상대적 크기 강조, 다중 클래스 분류에 적합(이미지 분류)

인공신경망이 활성화함수를 통해 출력된 값에 가중치를 계산하여 스스로 학습


텐서플로우-구글이 개발한 오픈소스 소프트웨어 라이브러리, 텐서(다차원 배열)의 흐름을 다루는 도구
데이터를 통해 복잡한 수치계산을 수행할 수 있는 도구로, 딥러닝 모델을 구축하고 훈련시키는 데 사용
순전파: 입력 데이터가 신경망을 거쳐 출력 생성
역전파: 손실을 최소화하기 위해 각 뉴런의 가중치에 대한 기울기를 계산(가중치가 손실에 얼마나 기여하는 지 계산)
손실계산: 생성된 출력과 실제 정답 간의 차이를 손실 함수를 통해 계산
옵티마이저: 역전파를 통해 얻은 기울기를 이용하여 어떤 방식으로 가중치를 업데이트할지를 결정


합성곱 신경망(CNN)
이미지, 비디오, 음성신호와 같은 데이터에서 특징을 자동으로 추출하고 분석하는 데 최적화된 딥러닝 모델
채널-rgb 3개의 채널로 구성
패딩-사이즈
스트라이드-이동 간격
풀링-특징맵의 크기를 감소


순환신경망(RNN)
순차적인 데이터를 처리하기 위해 설계된 인공신경망
이전의 정보를 기억하고 현재의 정보와 연결하여 처리
입력데이터가 길어지면 기울기 소실문제 발생


RSTM
RNN의 장기 의존성 문제를 해결하기 위해 개발된 순환 신경망
중요한 정보는 오래 기억, 불필요한 정보는 빠르게 잊는 능력을 가짐
망각게이트, 입력게이트, 출력게이트
