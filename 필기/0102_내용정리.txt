머신러닝

-지도학습:  예제와 정답을 제공해 학습
-비지도학습: 데이터를 입력하면 스스로 패턴을 학습
-강화학습: 보상 및 처벌의 형태로 학습

-회귀
독립변수와 출력변수 간의 관계를 모델링해 연속적인 수치 데이터를 예측

-선형회귀
독립변수와 종속변수 사이의 관계를 선형적으로 모델링>최적의 직선, 곡선 등 데이터의 패턴을 찾아서 예측
  *단순선형회귀: 하나의 독립변수만 사용
  *다중선형회귀: 여러 개의 독립변수 사용


-분류
기존 카테고리들을 학습하고, 이것을 기반으로 데이터 범주를 구분하여 경계를 나누는 것을 학습
  *로지스틱 회귀: 시그모이드 함수를 사용하여 0과 1 사이의 확률을 예측
	         간단하고 해석이 용이, 이진분류에 최적화
  *KNN: 가장 가까운 이웃들의 평균값을 기반으로 새로운 데이터 포인트의 값을 예측
          K가 작으면 과적합 위험높음, K가 크면 모델의 일반화 성능 저하 가능성 존재,
          특성들의 스케일을 맞추기 위해 정규화/표준화 필요
  *의사결정나무: 데이터를 여러 개의 하위 집합으로 분할하면서 최종적으로 어떤 클래스에 속하는지 판단
  *랜덤 포레스트: 같은 데이터에 의사결정나무 여러 개를 동시에 적용해 학습성능을 높이는 앙상블 학습기법
	          랜덤하게 샘플을 여러 번 추출하여 모델을 개별적으로 학습시킨 후, 결과를 취합
	          일부 특성만 무작위로 선택하여 학습시킴으로써 나무사이의 상관관계를 줄이고 다양성을 증가시킴
  *SVM: 데이터 공간에서 데이터를 두 클래스로 나누는 경계선인 초평면을 찾아내 데이터를 분리
           SVM은 학습 시 초평면과 서포트 벡터 사이의 마진을 최대화하는 방향으로 최적화
  *나이브 베이즈: 각 단어들이 독립적이라고 가정하고 각 단어의 빈도수만을 고려하여 판단하는 확률론적 분류모델
	          텍스트 분류나 스팸 필터링같은 분야에서 강력활용

-성능지표 분석
모델의 예측결과가 얼마나 정확한지, 효과적인지 평가하기 위해 지표들을 분석
모델의 강점과 약점을 파악하고, 개선을 위한 방향성 설정

예측/회귀: Loss, MSE, RMSE, MAE, R2(결정계수)
분류: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 Score
 

